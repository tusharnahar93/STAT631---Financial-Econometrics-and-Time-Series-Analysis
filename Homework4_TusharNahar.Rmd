---
title: "Homework 4"
author: "Tushar  Nahar"
date: "September 27, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
RLab 8.9


```{r}
library(copula)
cop_t_dim3 = tCopula(dim = 3, param = c(-0.6,0.75,0),
dispstr = "un", df = 1)
set.seed(5640)
rand_t_cop = rCopula(n = 500, copula = cop_t_dim3)
pairs(rand_t_cop)
cor(rand_t_cop)
```
Problem 1

(a)A Copula model of a Parametric Family has been sampled in the bove R code. The sample is obtained using the t copula family.

A t- copula family is specified using the correlation matrix and the tail index .

Correlation Matrix -
           [,1]        [,2]        [,3]
[1,]  1.0000000 -0.54999514  0.70707296
[2,] -0.5499951  1.00000000 -0.06538499
[3,]  0.7070730 -0.06538499  1.00000000

tail index-
1

(b)
The sample size is 500

Problem 2

(a)Th values of the components seem to be independent for the center values(non-tail values). However the scatter plots suggests that there is higher probability of finding outliers with other outliers which suggests that the components 2 and 3 may not be  independent.


(b)Signs of tail dependence can be seen in the scatter plots of the two components.Both upper and lower tail dependence can be seen from the plots

(c) A scatterplot with tail dependence will display the components to be more correlated in upper right and lower left corner of the graphs than in the body of the graph.

(d)
```{r}
cor.test(rand_t_cop[,1],rand_t_cop[,3])
```
The confidence interval does not include 0.75.Therefor there is a diffrence between the sample correlation and correlation between the copula mentioned. This maybe because random variables of copula and  sample have diffrent distributions.


Problem 3

```{r}
cop_normal_dim3 = normalCopula(dim = 3, param = c(-0.6,0.75,0),
dispstr = "un")
mvdc_normal = mvdc(copula = cop_normal_dim3, margins = rep("exp",3),
paramMargins = list(list(rate=2), list(rate=3),
list(rate=4)))
set.seed(5640)
rand_mvdc = rMvdc(n = 1000, mvdc = mvdc_normal)
pairs(rand_mvdc)
par(mfrow = c(2,2))
for(i in 1:3) plot(density(rand_mvdc[,i]))
setwd("C:/Users/tusha/Downloads")
```

(a) The marginal distribution for three components in mvdc is is exponential distribution.The expected value is 0.5 ,0.333 and 0.25 respectively

(b) Variables 2 and 3 independent since they are scattered equally in all directions in the scatter plot.


Problem 4

```{r}
library(MASS) # for fitdistr() and kde2d() functions
library(copula) # for copula functions
library(fGarch) # for standardized t density
setwd("C:/Users/tusha/Downloads")
netRtns = read.csv("IBM_SP500_04_14_daily_netRtns.csv", header = T)
ibm = netRtns[,2]
sp500 = netRtns[,3]
est.ibm = as.numeric( fitdistr(ibm,"t")$estimate )
est.sp500 = as.numeric( fitdistr(sp500,"t")$estimate )
est.ibm[2] = est.ibm[2] * sqrt( est.ibm[3] / (est.ibm[3]-2) )
est.sp500[2] = est.sp500[2] * sqrt(est.sp500[3] / (est.sp500[3]-2) )
cor_tau = cor(ibm, sp500, method = "kendall")
omega = sin((pi/2)*cor_tau)
```
The line 12 of the code is completed using the following relation

????(Yi, Yj) =2/??*arcsin(??ij)

we get the relation (wij)=Sin(??/2* ????(Yi, Yj))

```{r}
omega
```

Omega is 0.7018346


Problem 5

```{r}
cop_t_dim2 = tCopula(omega, dim = 2, dispstr = "un", df = 4)
data1 = cbind(pstd(ibm, est.ibm[1], est.ibm[2], est.ibm[3]),
pstd(sp500, est.sp500[1], est.sp500[2], est.sp500[3]))
n = nrow(netRtns) ; n
data2 = cbind(rank(ibm)/(n+1), rank(sp500)/(n+1))
ft1 = fitCopula(cop_t_dim2, data1, method="ml", start=c(omega,4) )
ft2 = fitCopula(cop_t_dim2, data2, method="ml", start=c(omega,4) )
ft1
ft2
```
(a)fit 1 is obtained using an estimation method called parametric psuedo naximum likelihood
fit 2 os obtained using an estimation method called non parametric psuedo likelihood

In the fit 1 the marginal distribution fucntion value is estimated by estimating the parameters of a parametric distribution function 

In fit 2 the parameters are estimated using the emperical CDF 

(b) In real life , as observed with the current example , when there are huge number of data points there would be no difference between the two estimates.


Problem 6
(a)
```{r}
mvdc_t_t = mvdc( cop_t_dim2, c("std","std"), list(
list(mean=est.ibm[1],sd=est.ibm[2],nu=est.ibm[3]),
list(mean=est.sp500[1],sd=est.sp500[2],nu=est.sp500[3])))
start = c(est.ibm, est.sp500, ft1@estimate)
objFn = function(param) -loglikMvdc(param,cbind(ibm,sp500),mvdc_t_t)
tic = proc.time()
ft = optim(start, objFn, method="L-BFGS-B",
lower = c(-.1,0.001,2.2, -0.1,0.001,2.2, 0.2,2.5),
upper = c( .1, 10, 15, 0.1, 10, 15, 0.9, 15) )
toc = proc.time()
total_time = toc - tic ; total_time[3]/60
ft
```
The following are the estimated parameters for the copula
(0.06504701,1.37982781,3.35792653,0.07422142,1.80751161,2.33415929,0.70421613,2.96934977)

(b)
```{r}
est.ibm[1]
est.ibm[2]
est.ibm[3]
est.sp500[1]
est.sp500[2]
est.sp500[3]

```
The following are the estimated parameters for the marginal distribution

IBM

Mean=0.05015879
Variance =1.42823
df=3.254383

S and P 500

Mean=0.05015879
Variance =1.42823
df=3.254383

(c) The method was parametric psuedo maximum likelihood

(d)The lower tail dependence for t -copula can be calculated using the tail dependence formula for a bivariate t copula taking v=4 and rho=0.7018346
0.3922

Problem 7
```{r}
fnorm = fitCopula(copula=normalCopula(dim=2),data=data1,method="ml")
ffrank = fitCopula(copula = frankCopula(3, dim = 2),
data = data1, method = "ml")
fclayton = fitCopula(copula = claytonCopula(1, dim=2),
data = data1, method = "ml")
fgumbel = fitCopula(copula = gumbelCopula(3, dim=2),
data = data1, method = "ml")
fjoe = fitCopula(copula=joeCopula(2,dim=2),data=data1,method="ml")
Udex = (1:n)/(n+1)
Cn = C.n(u=cbind(rep(Udex,n),rep(Udex,each=n)), X=data1, method="C")
EmpCop = expression(contour(Udex, Udex, matrix(Cn, n, n),
col = 2, add = TRUE))
par(mfrow=c(2,3), mgp = c(2.5,1,0))
contour(tCopula(param=ft$par[7],dim=2,df=round(ft$par[8])),
pCopula, main = expression(hat(C)[t]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
contour(normalCopula(param=fnorm@estimate[1], dim = 2),
pCopula, main = expression(hat(C)[Gauss]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
contour(frankCopula(param=ffrank@estimate[1], dim = 2),
pCopula, main = expression(hat(C)[Fr]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
contour(claytonCopula(param=fclayton@estimate[1], dim = 2),
pCopula, main = expression(hat(C)[Cl]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
contour(gumbelCopula(param=fgumbel@estimate[1], dim = 2),
pCopula, main = expression(hat(C)[Gu]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
contour(joeCopula(param=fjoe@estimate[1], dim = 2),
pCopula, main = expression(hat(C)[Joe]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
```
Yes there is a diffrence between parametric estimates . Some curves fit better than the other over diffrent value ofcomponents of the copula. t-copula has the closest fit to the emperical copula over all values of u1hat and u2hat

```{r}
contour(tCopula(param=ft$par[7],dim=2,df=round(ft$par[8])),
pCopula, main = expression(hat(C)[t]),
xlab = expression(hat(U)[1]), ylab = expression(hat(U)[2]) )
eval(EmpCop)
```


Problem 8
```{r}
par(mfrow=c(2,3), mgp = c(2.5,1,0))
contour(tCopula(param=ft$par[7],dim=2,df=round(ft$par[8])),
dCopula, main = expression(hat(c)[t]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
contour(normalCopula(param=fnorm@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Gauss]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
contour(frankCopula(param=ffrank@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Fr]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
contour(claytonCopula(param=fclayton@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Cl]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
contour(gumbelCopula(param=fgumbel@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Gu]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
contour(joeCopula(param=fjoe@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Joe]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)
```
Yes there is diffrence between the estimates of the copula density.Frank Copula seems to have an estimate closes to that of KDE

```{r}
contour(frankCopula(param=ffrank@estimate[1], dim = 2),
dCopula, main = expression(hat(c)[Fr]),
nlevels=25, xlab=expression(hat(U)[1]),ylab=expression(hat(U)[2]))
contour(kde2d(data1[,1],data1[,2]), col = 2, add = TRUE)

```

Problem 9

```{r}
aic_t=-2*ft1@loglik + 2*length(ft1@estimate)
aic_normal = -2*fnorm@loglik + 2*length(fnorm@estimate)
aic_clayton=-2*fclayton@loglik + 2*length(fnorm@estimate)
aic_gumbel = -2*fgumbel@loglik + 2 * length(fgumbel@estimate)
aic_joe = -2*fjoe@loglik + 2 * length(fjoe@estimate)
aic_t
aic_normal
aic_gumbel
aic_clayton
aic_joe
```

t-copula model with aic of  -1930.338 has the best fit